{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b101930",
   "metadata": {},
   "source": [
    "## ANN Observations\n",
    "\n",
    "- ANN captures non-linear relationships\n",
    "- Performance comparable to ensemble methods on tabular data\n",
    "- Requires careful preprocessing and tuning\n",
    "- Increased complexity without guaranteed superiority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7098ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc789be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\FailureSense_MLProj\\failuresense\\data\\raw\\ai4i2020.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a275fa",
   "metadata": {},
   "source": [
    "prepre X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c346966",
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_COLUMNS = [\"UDI\", \"TWF\", \"HDF\", \"PWF\", \"OSF\", \"RNF\"]\n",
    "TARGET = \"Machine failure\"\n",
    "\n",
    "X = df.drop(columns=DROP_COLUMNS + [TARGET])\n",
    "y = df[TARGET]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da235f44",
   "metadata": {},
   "source": [
    "train - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d6f3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255bf60b",
   "metadata": {},
   "source": [
    "preprocessing (same as ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14aa059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\n",
    "    \"Air temperature [K]\",\n",
    "    \"Process temperature [K]\",\n",
    "    \"Rotational speed [rpm]\",\n",
    "    \"Torque [Nm]\",\n",
    "    \"Tool wear [min]\"\n",
    "]\n",
    "\n",
    "categorical_features = [\"Type\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c49b6",
   "metadata": {},
   "source": [
    "reshape for cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edee536f",
   "metadata": {},
   "source": [
    "CNN expects 3D input:\n",
    "(samples, timesteps, channels)\n",
    "\n",
    "We treat features as 1D sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27b9417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = X_train_processed.reshape(\n",
    "    X_train_processed.shape[0],\n",
    "    X_train_processed.shape[1],\n",
    "    1\n",
    ")\n",
    "\n",
    "X_test_cnn = X_test_processed.reshape(\n",
    "    X_test_processed.shape[0],\n",
    "    X_test_processed.shape[1],\n",
    "    1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd5865",
   "metadata": {},
   "source": [
    "build 1d cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ee9934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACSS\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation=\"relu\",\n",
    "           input_shape=(X_train_cnn.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954efa7",
   "metadata": {},
   "source": [
    "compile cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db15f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6ff2a",
   "metadata": {},
   "source": [
    "train cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34fbcb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9578 - loss: 0.2699 - val_accuracy: 0.9656 - val_loss: 0.1553\n",
      "Epoch 2/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9663 - loss: 0.1311 - val_accuracy: 0.9656 - val_loss: 0.1158\n",
      "Epoch 3/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9683 - loss: 0.1053 - val_accuracy: 0.9675 - val_loss: 0.1056\n",
      "Epoch 4/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9702 - loss: 0.0973 - val_accuracy: 0.9700 - val_loss: 0.1013\n",
      "Epoch 5/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.0922 - val_accuracy: 0.9675 - val_loss: 0.0960\n",
      "Epoch 6/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0894 - val_accuracy: 0.9681 - val_loss: 0.0944\n",
      "Epoch 7/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0861 - val_accuracy: 0.9675 - val_loss: 0.0933\n",
      "Epoch 8/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9730 - loss: 0.0847 - val_accuracy: 0.9712 - val_loss: 0.0884\n",
      "Epoch 9/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9730 - loss: 0.0825 - val_accuracy: 0.9719 - val_loss: 0.0873\n",
      "Epoch 10/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9739 - loss: 0.0812 - val_accuracy: 0.9712 - val_loss: 0.0859\n",
      "Epoch 11/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9752 - loss: 0.0799 - val_accuracy: 0.9688 - val_loss: 0.0877\n",
      "Epoch 12/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9758 - loss: 0.0801 - val_accuracy: 0.9725 - val_loss: 0.0856\n",
      "Epoch 13/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9747 - loss: 0.0788 - val_accuracy: 0.9681 - val_loss: 0.0887\n",
      "Epoch 14/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9745 - loss: 0.0779 - val_accuracy: 0.9731 - val_loss: 0.0845\n",
      "Epoch 15/15\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9748 - loss: 0.0779 - val_accuracy: 0.9706 - val_loss: 0.0875\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit(\n",
    "    X_train_cnn,\n",
    "    y_train,\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26725e8b",
   "metadata": {},
   "source": [
    "evaluate cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "606c93bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_prob_cnn = cnn_model.predict(X_test_cnn).ravel()\n",
    "y_pred_cnn = (y_prob_cnn >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b88c01ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1929,    3],\n",
       "       [  58,   10]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2727afbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1932\n",
      "           1       0.77      0.15      0.25        68\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.87      0.57      0.62      2000\n",
      "weighted avg       0.96      0.97      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_cnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8fc905f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9478062964316161"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_prob_cnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7be6dd",
   "metadata": {},
   "source": [
    "### CNN Observations\n",
    "\n",
    "- CNN was applied using a 1D convolution over feature sequences\n",
    "- Designed primarily for spatial/temporal data, CNN offers limited advantage here\n",
    "- Performance comparable to ANN but not superior to ensemble models\n",
    "- Demonstrates experimental adaptation rather than preferred production approach\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
